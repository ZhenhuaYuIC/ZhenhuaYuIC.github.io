---
layout: archive
title: "Research"
permalink: /research/
author_profile: true
toc: true
---

The aim of our research group is to develop robots that can interact with the physical world safely and robustly. We leverage high-resolution tactile sensing, visual understanding of objects in the scenes and robot learning to enable the robots to have such desirable capabilities. 

{% include toc %}

<!-- # Research Keywords -->

<!-- <br />
<img align="center" width="800" src="{{ site.url }}/images/WordCloudResearch.png" alt="...">
<br />
 -->
# High-resolution tactile sensing

<img align="left" width="200" style="margin-right: 10px" src="{{ site.url }}/images/research/GelTip.jpeg" alt="...">
GelTip: A Finger-shaped Optical Tactile Sensor for Robotic Manipulation <br />
D.F. Gomes, Z. Lin, **S. Luo**. IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) 2020. <br />
[[paper]](https://arxiv.org/abs/2008.05404) [[website]](https://danfergo.github.io/geltip/) [[STL files]](https://danfergo.github.io/geltip/geltip2020_parts.zip)

<br />
<br />
<img align="left" width="200" style="margin-right: 10px" src="{{ site.url }}/images/research/exp_world_blocks.gif" alt="...">
Blocks World of Touch: Exploiting the Advantages of All-around Finger Sensing in Robot Grasping <br />
D.F. Gomes, Z. Lin, **S. Luo**. Frontiers in Robotics and AI 7, 541661, 2020. <br />
[[paper]](https://www.frontiersin.org/articles/10.3389/frobt.2020.541661/full) [[website]](https://danfergo.github.io/geltip/)

<br />
# Simulation of optical tactile sensors
<img align="left" width="200" style="margin-right: 10px" src="{{ site.url }}/images/research/simulation_GelSight.gif" alt="...">
Generation of gelsight tactile images for sim2real learning <br />
D.F. Gomes, P. Paoletti, **S. Luo**. IEEE Robotics and Automation Letters, 6(2), pp.4177-4184. & The International Conference on Robotics and Automation (ICRA) 2021. <br />
[[paper]](https://arxiv.org/abs/2101.07169) [[website]](https://danfergo.github.io/gelsight-simulation/) [[code]](https://github.com/danfergo/gelsight_simulation)
<br />
<br />
<img align="left" width="200" style="margin-right: 10px" src="{{ site.url }}/images/research/ICRA2022_Tudor.png" alt="...">
Reducing Tactile Sim2Real Domain Gaps via Deep Texture Generation Networks <br />
T. Jianu, D.F. Gomes, P. Paoletti, **S. Luo**. IEEE International Conference on Robotics and Automation (ICRA) 2022. <br />
[[paper]](https://arxiv.org/abs/2112.01807) [[website]](https://danfergo.github.io/gelsight-simulation/)
<br />
<br />
<img align="left" width="200" style="margin-right: 10px" src="{{ site.url }}/images/research/Tacchi.gif" alt="...">
Tacchi: A Pluggable and Low Computational Cost Elastomer Deformation Simulator for Optical Tactile Sensors <br />
Z. Chen, S. Zhang, **S. Luo**, F. Sun, B. Fang IEEE Robotics and Automation Letters, 2023. <br />
[[paper]](https://arxiv.org/pdf/2301.08343.pdf) [[website]](https://github.com/zixichen007115/Tacchi)

<br />
<br />
<br />
<br />
# Robot Perception of Flexible Materials with Vision and Tactile Sensing

<img align="left" width="200" style="margin-right: 10px" src="{{ site.url }}/images/research/LeszekIROS2022.gif" alt="...">
Visual-Tactile Multimodality for Following Deformable Linear Objects Using Reinforcement Learning <br />
L. Pecyna, S. Dong, **S. Luo**. IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) 2022. <br />
[[paper]](https://arxiv.org/abs/2204.00117) [[code]](https://github.com/lpecyna/SoftSlidingGym)
<br />
<br />
<br />
<br />
<br />
<img align="left" width="200" style="margin-right: 10px" src="{{ site.url }}/images/research/TactileAttention.png" alt="...">
Spatio-temporal attention model for tactile texture recognition <br />
G. Cao, Y. Zhou, D. Bollegala, **S. Luo**. IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) 2020. [[paper]](https://arxiv.org/abs/2008.04442)
<br />
<br />
<img align="left" width="200" style="margin-right: 10px" src="{{ site.url }}/images/research/T2S_S2T.png" alt="...">
"Touching to See" and "Seeing to Feel": Robotic Cross-modal SensoryData Generation for Visual-Tactile Perception <br />
J.-T. Lee, D. Bollegala, **S. Luo**. IEEE International Conference on Robotics and Automation (ICRA) 2019. <br />
[[paper]](https://arxiv.org/abs/1902.06273)
<br />
<br />
<img align="left" width="200" style="margin-right: 10px" src="{{ site.url }}/images/research/iCLAP.png" alt="...">
iCLAP: Shape Recognition by Combining Proprioception and Touch Sensing <br />
**S. Luo**, W. Mou, K. Althoefer and H. Liu. Autonomous Robots 2019. <br />
[[paper]](https://arxiv.org/pdf/1806.07507.pdf) <br />
Iterative closest labeled point for tactile object shape recognition
**S. Luo**, W. Mou, K. Althoefer and H. Liu. IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) 2016.
[[paper]](https://arxiv.org/abs/1708.04436)

<img align="left" width="200" style="margin-right: 10px" src="{{ site.url }}/images/research/ViTac_ICRA2018.png" alt="...">
ViTac: Feature Sharing between Vision and Tactile Sensing for Cloth Texture Recognition <br />
**S. Luo**, W. Yuan, E. Adelson, A. G. Cohn and R. Fuentes. IEEE International Conference on Robotics and Automation (ICRA) 2018. [[paper]](https://arxiv.org/pdf/1802.07490.pdf) [[dataset]](https://drive.google.com/drive/folders/1uwPDUm7cDtBGJUQRe4H1KeQwcJQrnMJF?usp=share_link) <br />

<br />
<br />
# Robot Perception of Transparent Objects with Vision and Tactile Sensing

<img align="left" width="200" style="margin-right: 10px" src="{{ site.url }}/images/research/A4T.gif" alt="...">
A4T: Hierarchical Affordance Detection for Transparent Objects Depth Reconstruction and Manipulation  <br />
J. Jiang, G. Cao, T.-T. Do, **S. Luo**. IEEE Robotics and Automation Letters & IEEE 18th International Conference on Automation Science and Engineering (CASE) 2022 - **Best Student Paper Award Finalist**. [[paper]](https://arxiv.org/abs/2008.04442) [[website]](https://sites.google.com/view/affordance4trans) [[dataset]](https://sites.google.com/view/affordance4trans) <br />
<br />
<br />
<img align="left" width="200" style="margin-right: 10px" src="{{ site.url }}/images/research/Where2Touch.gif" alt="...">
Where shall I touch? Vision-Guided Tactile Poking for Transparent Object Grasping <br />
J. Jiang, G. Cao, A. Butterworth, T.-T. Do, **S. Luo**. IEEE/ASME Transactions on Mechatronics 2022. <br />
[[paper]](https://arxiv.org/abs/2208.09743) [[website]](https://sites.google.com/view/tactilepoking) [[code]](https://github.com/3PTelephant/TransparentObjectRender) [[dataset]](https://drive.google.com/drive/folders/1ReuoAuIm4R3VkUpiQhKKpIL4wGo1TQWj) <br />

<br />
<br />
# Minorities Matter: Long-tailed Object Recogntion
<img align="left" width="200" style="margin-right: 10px" src="{{ site.url }}/images/research/Gumbel.jpg" alt="...">
Long-tailed Instance Segmentation using Gumbel Optimized Loss <br />
K. P. Alexandridis, J. Deng, A. Nguyen, **S. Luo**. European Conference on Computer Vision (ECCV) 2022. <br />
[[paper]](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136700349.pdf) [[code]](https://github.com/kostas1515/GOL) <br />
